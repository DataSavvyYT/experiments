{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f707942e93bc45b6ab3f9461870cff44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b920c93cddef4960a9c5c56b9526e5a3",
              "IPY_MODEL_6ce20d4be53346fa837c2e71e0b4c641",
              "IPY_MODEL_06e62563acd04aa295f3e1ad21eb6179"
            ],
            "layout": "IPY_MODEL_35124b7d84d54eaa8b2aa8033d4f06bf"
          }
        },
        "b920c93cddef4960a9c5c56b9526e5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822610a2023a471891435b5c9ea7614f",
            "placeholder": "​",
            "style": "IPY_MODEL_cd53c860094a4c53b13e8c3e98efcf29",
            "value": "Epoch 1/2: 100%"
          }
        },
        "6ce20d4be53346fa837c2e71e0b4c641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f423c84a481046bb808aaa20fa982e24",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1db7189134eb44c782ab3fdedb0ac389",
            "value": 125
          }
        },
        "06e62563acd04aa295f3e1ad21eb6179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_013e88bb4a514425ba5a5d246f666921",
            "placeholder": "​",
            "style": "IPY_MODEL_a66b0d42ff184634a884d6af78bd0964",
            "value": " 125/125 [00:27&lt;00:00,  4.89it/s, loss=4.5528, avg_loss=4.7668]"
          }
        },
        "35124b7d84d54eaa8b2aa8033d4f06bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822610a2023a471891435b5c9ea7614f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd53c860094a4c53b13e8c3e98efcf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f423c84a481046bb808aaa20fa982e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db7189134eb44c782ab3fdedb0ac389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "013e88bb4a514425ba5a5d246f666921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66b0d42ff184634a884d6af78bd0964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4015e7232d894953963de5429029029c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81f672f9d10e49f68baf653e5ac10570",
              "IPY_MODEL_7a7a05a4833f43a48a6f7f394b756eaf",
              "IPY_MODEL_e28734f75d6843f89c7c4ae67d0f4bf1"
            ],
            "layout": "IPY_MODEL_3d24032ddbd34e899811b6f11abb4b64"
          }
        },
        "81f672f9d10e49f68baf653e5ac10570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eac22fd6ea3449fb63cfb009e9ce079",
            "placeholder": "​",
            "style": "IPY_MODEL_d70d49353a3c4cb2b5d28f0938c38bee",
            "value": "Epoch 2/2: 100%"
          }
        },
        "7a7a05a4833f43a48a6f7f394b756eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39d0539711d4d18a945f9fcdd10d5aa",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fd674d9dc934327b084edb8b9bd0919",
            "value": 125
          }
        },
        "e28734f75d6843f89c7c4ae67d0f4bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b11430d2e942b18d82aaddc8410e58",
            "placeholder": "​",
            "style": "IPY_MODEL_fc31a2f5a6854a4b9bb9d0971e9b35e3",
            "value": " 125/125 [00:27&lt;00:00,  4.91it/s, loss=4.2482, avg_loss=2.3748]"
          }
        },
        "3d24032ddbd34e899811b6f11abb4b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eac22fd6ea3449fb63cfb009e9ce079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70d49353a3c4cb2b5d28f0938c38bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b39d0539711d4d18a945f9fcdd10d5aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd674d9dc934327b084edb8b9bd0919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2b11430d2e942b18d82aaddc8410e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc31a2f5a6854a4b9bb9d0971e9b35e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataSavvyYT/experiments/blob/main/paper_implement/dev/1_mrinal_mtech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers datasets sentence-transformers torch accelerate"
      ],
      "metadata": {
        "id": "15Lqhuu9EfYO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    T5ForConditionalGeneration,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "metadata": {
        "id": "EyAfWp7FEh9P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "wLnV1PPYEkum"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T78OVKbwEnpR",
        "outputId": "e2ce8018-c7ee-4fc5-baf2-a2a86d34233e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== Configuration ====================\n",
        "class Config:\n",
        "    # Model parameters\n",
        "    llm_name = \"google/flan-t5-base\"  # Using base instead of XXL for Colab\n",
        "    encoder_name = \"BAAI/bge-base-en-v1.5\"  # BGE encoder as per paper\n",
        "\n",
        "    # Training parameters\n",
        "    batch_size = 4\n",
        "    learning_rate = 1e-4\n",
        "    num_epochs = 2\n",
        "    warmup_ratio = 0.05\n",
        "    max_input_length = 256\n",
        "    max_encoder_length = 512\n",
        "    max_output_length = 128\n",
        "\n",
        "    # PPlug specific\n",
        "    embedding_dim = 768  # BGE base embedding dimension\n",
        "    llm_hidden_size = 768  # T5-base hidden size\n",
        "    num_personal_tokens = 1  # Number of personal embedding tokens\n",
        "\n",
        "    # Data parameters\n",
        "    max_histories = 20  # Limit user histories for memory efficiency\n",
        "    sample_size = 500  # Reduced dataset size for Colab\n"
      ],
      "metadata": {
        "id": "H672ZcQYEqEZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()"
      ],
      "metadata": {
        "id": "4xW2x8MlEtrd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== Data Loading ====================\n",
        "class LaMP_Dataset:\n",
        "    \"\"\"Simplified LaMP dataset loader for demonstration\"\"\"\n",
        "\n",
        "    def __init__(self, task=\"LaMP-2\", split=\"train\", sample_size=500):\n",
        "        \"\"\"\n",
        "        Load LaMP dataset (using LaMP-2: Movie Tagging as example)\n",
        "        For full implementation, download from: https://lamp-benchmark.github.io/download\n",
        "        \"\"\"\n",
        "        print(f\"Loading {task} {split} dataset...\")\n",
        "\n",
        "        # For demo: Create synthetic data mimicking LaMP structure\n",
        "        # In production, load from: https://huggingface.co/datasets/LaMP/LaMP-2\n",
        "        self.data = self._create_demo_data(sample_size)\n",
        "\n",
        "    def _create_demo_data(self, sample_size):\n",
        "        \"\"\"Create synthetic data for demonstration\"\"\"\n",
        "        data = []\n",
        "\n",
        "        # Simulate movie tagging task\n",
        "        movie_genres = ['Action', 'Comedy', 'Drama', 'Horror', 'Sci-Fi',\n",
        "                       'Romance', 'Thriller', 'Documentary']\n",
        "\n",
        "        for i in range(sample_size):\n",
        "            user_id = f\"user_{i % 50}\"  # 50 unique users\n",
        "\n",
        "            # Create user histories (previous movie ratings)\n",
        "            histories = []\n",
        "            num_hist = np.random.randint(5, 20)\n",
        "            for j in range(num_hist):\n",
        "                hist = {\n",
        "                    'text': f\"Movie: Sample Film {j}. Description: A {np.random.choice(movie_genres).lower()} film.\",\n",
        "                    'label': np.random.choice(movie_genres)\n",
        "                }\n",
        "                histories.append(hist)\n",
        "\n",
        "            # Current input\n",
        "            current_movie = f\"Movie: Test Film {i}. Description: An exciting {np.random.choice(movie_genres).lower()} adventure.\"\n",
        "            target_genre = np.random.choice(movie_genres)\n",
        "\n",
        "            data.append({\n",
        "                'user_id': user_id,\n",
        "                'input': current_movie,\n",
        "                'output': target_genre,\n",
        "                'histories': histories\n",
        "            })\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n"
      ],
      "metadata": {
        "id": "QcWPKR9_E4vg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== User Behavior Encoder ====================\n",
        "class UserBehaviorEncoder(nn.Module):\n",
        "    \"\"\"Encodes user historical behaviors using BGE model\"\"\"\n",
        "\n",
        "    def __init__(self, encoder_name):\n",
        "        super().__init__()\n",
        "        self.encoder = SentenceTransformer(encoder_name)\n",
        "        # Freeze encoder parameters as per paper\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def encode_histories(self, histories):\n",
        "        \"\"\"Encode list of historical behaviors\"\"\"\n",
        "        with torch.no_grad():\n",
        "            embeddings = self.encoder.encode(\n",
        "                histories,\n",
        "                convert_to_tensor=True,\n",
        "                show_progress_bar=False\n",
        "            )\n",
        "        return embeddings\n",
        "\n",
        "    def encode_input(self, inputs, trainable=True):\n",
        "        \"\"\"Encode current input (can be trainable)\"\"\"\n",
        "        if trainable:\n",
        "            embeddings = self.encoder.encode(\n",
        "                inputs,\n",
        "                convert_to_tensor=True,\n",
        "                show_progress_bar=False\n",
        "            )\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                embeddings = self.encoder.encode(\n",
        "                    inputs,\n",
        "                    convert_to_tensor=True,\n",
        "                    show_progress_bar=False\n",
        "                )\n",
        "        return embeddings\n"
      ],
      "metadata": {
        "id": "moAaHzueE9o-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== Input-aware Personal Aggregator ====================\n",
        "class PersonalAggregator(nn.Module):\n",
        "    \"\"\"Aggregates user histories into personal embedding with attention\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, llm_hidden_size):\n",
        "        super().__init__()\n",
        "        # Project from encoder space to LLM space\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, llm_hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(llm_hidden_size, llm_hidden_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, history_embeddings, input_embedding):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            history_embeddings: [num_histories, embedding_dim]\n",
        "            input_embedding: [embedding_dim]\n",
        "        Returns:\n",
        "            personal_embedding: [llm_hidden_size]\n",
        "        \"\"\"\n",
        "        # Compute attention weights (Equation 3 in paper)\n",
        "        # wi = exp(xu^T * hu_i) / sum(exp(xu^T * hu_k))\n",
        "        scores = torch.matmul(history_embeddings, input_embedding)  # [num_histories]\n",
        "        weights = torch.softmax(scores, dim=0)  # [num_histories]\n",
        "\n",
        "        # Weighted aggregation (Equation 4 in paper)\n",
        "        # Pu = sum(wi * Proj(hu_i))\n",
        "        projected_histories = self.projector(history_embeddings)  # [num_histories, llm_hidden_size]\n",
        "        personal_embedding = torch.sum(\n",
        "            weights.unsqueeze(1) * projected_histories,\n",
        "            dim=0\n",
        "        )  # [llm_hidden_size]\n",
        "\n",
        "        return personal_embedding, weights\n"
      ],
      "metadata": {
        "id": "0P_Kz3LuFEai"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    T5ForConditionalGeneration,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "# ==================== PPlug Model ====================\n",
        "class PPlugModel(nn.Module):\n",
        "    \"\"\"Complete PPlug model for personalized LLM generation\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # Load LLM (frozen)\n",
        "        self.llm = T5ForConditionalGeneration.from_pretrained(config.llm_name)\n",
        "        self.llm_tokenizer = AutoTokenizer.from_pretrained(config.llm_name)\n",
        "\n",
        "        # Freeze LLM parameters\n",
        "        for param in self.llm.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # User behavior encoder\n",
        "        self.behavior_encoder = UserBehaviorEncoder(config.encoder_name)\n",
        "\n",
        "        # Personal aggregator (trainable)\n",
        "        self.personal_aggregator = PersonalAggregator(\n",
        "            config.embedding_dim,\n",
        "            config.llm_hidden_size\n",
        "        )\n",
        "\n",
        "        # Instruction embedding (trainable)\n",
        "        self.instruction_embedding = nn.Parameter(\n",
        "            torch.randn(1, config.num_personal_tokens, config.llm_hidden_size)\n",
        "        )\n",
        "\n",
        "        self.config = config\n",
        "\n",
        "    def get_personal_embedding(self, histories, current_input):\n",
        "        \"\"\"Generate personal embedding for a user\"\"\"\n",
        "        # Encode histories\n",
        "        history_texts = [h['text'] for h in histories[:self.config.max_histories]]\n",
        "        history_embeddings = self.behavior_encoder.encode_histories(history_texts)\n",
        "\n",
        "        # Fix: Clone and detach history_embeddings to resolve \"Inference tensors cannot be saved for backward\" error\n",
        "        history_embeddings = history_embeddings.clone().detach()\n",
        "\n",
        "        # Encode current input\n",
        "        input_embedding = self.behavior_encoder.encode_input([current_input], trainable=True)[0]\n",
        "\n",
        "        # Aggregate into personal embedding\n",
        "        personal_embedding, attention_weights = self.personal_aggregator(\n",
        "            history_embeddings.to(self.instruction_embedding.device),\n",
        "            input_embedding.to(self.instruction_embedding.device)\n",
        "        )\n",
        "\n",
        "        return personal_embedding, attention_weights\n",
        "\n",
        "    def forward(self, batch):\n",
        "        \"\"\"\n",
        "        Forward pass with personal embeddings\n",
        "        \"\"\"\n",
        "        batch_size = len(batch['input'])\n",
        "        device = self.instruction_embedding.device\n",
        "\n",
        "        # Get LLM input embeddings\n",
        "        input_ids = self.llm_tokenizer(\n",
        "            batch['input'],\n",
        "            max_length=self.config.max_input_length,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        ).input_ids.to(device)\n",
        "\n",
        "        # Get target labels\n",
        "        labels = self.llm_tokenizer(\n",
        "            batch['output'],\n",
        "            max_length=self.config.max_output_length,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        ).input_ids.to(device)\n",
        "        labels[labels == self.llm_tokenizer.pad_token_id] = -100\n",
        "\n",
        "        # Get original input embeddings from LLM\n",
        "        inputs_embeds = self.llm.encoder.embed_tokens(input_ids)  # [batch, seq_len, hidden]\n",
        "\n",
        "        # Create personal embeddings for each sample in batch\n",
        "        personal_embeds_list = []\n",
        "        for i in range(batch_size):\n",
        "            personal_emb, _ = self.get_personal_embedding(\n",
        "                batch['histories'][i],\n",
        "                batch['input'][i]\n",
        "            )\n",
        "            personal_embeds_list.append(personal_emb)\n",
        "\n",
        "        personal_embeds = torch.stack(personal_embeds_list).unsqueeze(1)  # [batch, 1, hidden]\n",
        "\n",
        "        # Concatenate: [Instruction; Personal_Embedding; Input_Embeddings]\n",
        "        instruction_embeds = self.instruction_embedding.expand(batch_size, -1, -1)\n",
        "        final_embeds = torch.cat([\n",
        "            instruction_embeds,\n",
        "            personal_embeds,\n",
        "            inputs_embeds\n",
        "        ], dim=1)\n",
        "\n",
        "        # Forward through LLM\n",
        "        outputs = self.llm(\n",
        "            inputs_embeds=final_embeds,\n",
        "            labels=labels,\n",
        "            return_dict=True\n",
        "        )\n",
        "\n",
        "        return outputs.loss, outputs.logits\n",
        "\n",
        "    def generate(self, input_text, histories, max_length=50):\n",
        "        \"\"\"Generate personalized output\"\"\"\n",
        "        device = self.instruction_embedding.device\n",
        "\n",
        "        # Get personal embedding\n",
        "        personal_emb, attention_weights = self.get_personal_embedding(histories, input_text)\n",
        "\n",
        "        # Prepare input\n",
        "        input_ids = self.llm_tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.config.max_input_length,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        ).input_ids.to(device)\n",
        "\n",
        "        inputs_embeds = self.llm.encoder.embed_tokens(input_ids)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        personal_embeds = personal_emb.unsqueeze(0).unsqueeze(0)\n",
        "        final_embeds = torch.cat([\n",
        "            self.instruction_embedding,\n",
        "            personal_embeds,\n",
        "            inputs_embeds\n",
        "        ], dim=1)\n",
        "\n",
        "        # Generate\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.llm.generate(\n",
        "                inputs_embeds=final_embeds,\n",
        "                max_length=max_length,\n",
        "                num_beams=4,  # Beam search as per paper\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        output_text = self.llm_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "        return output_text, attention_weights\n"
      ],
      "metadata": {
        "id": "iiA_QidzFISV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== Training ====================\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Custom collate function for DataLoader\"\"\"\n",
        "    return {\n",
        "        'input': [item['input'] for item in batch],\n",
        "        'output': [item['output'] for item in batch],\n",
        "        'histories': [item['histories'] for item in batch],\n",
        "        'user_id': [item['user_id'] for item in batch]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "tGtr1W6CFRdy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_pplug(model, train_dataset, config):\n",
        "    \"\"\"Train PPlug model\"\"\"\n",
        "\n",
        "    # Create dataloader\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    # Optimizer (only trainable parameters)\n",
        "    optimizer = AdamW(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=config.learning_rate\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    num_training_steps = len(train_loader) * config.num_epochs\n",
        "    num_warmup_steps = int(num_training_steps * config.warmup_ratio)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "       # Training loop\n",
        "    model.train()\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        epoch_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.num_epochs}\")\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            # Forward pass\n",
        "            loss, logits = model(batch)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Update metrics\n",
        "            epoch_loss += loss.item()\n",
        "            global_step += 1\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'avg_loss': f'{epoch_loss/global_step:.4f}'\n",
        "            })\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} completed. Average loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "HbK6ABNLFTjl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== Evaluation ====================\n",
        "def evaluate_pplug(model, test_dataset, num_samples=10):\n",
        "    \"\"\"Evaluate PPlug model on test set\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    ground_truths = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EVALUATION EXAMPLES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for i in range(min(num_samples, len(test_dataset))):\n",
        "        sample = test_dataset[i]\n",
        "\n",
        "        # Generate prediction\n",
        "        pred_text, attention_weights = model.generate(\n",
        "            sample['input'],\n",
        "            sample['histories'],\n",
        "            max_length=config.max_output_length\n",
        "        )\n",
        "\n",
        "        predictions.append(pred_text)\n",
        "        ground_truths.append(sample['output'])\n",
        "\n",
        "        # Print examples\n",
        "        if i < 5:\n",
        "            print(f\"\\n--- Example {i+1} ---\")\n",
        "            print(f\"User ID: {sample['user_id']}\")\n",
        "            print(f\"Input: {sample['input'][:100]}...\")\n",
        "            print(f\"Predicted: {pred_text}\")\n",
        "            print(f\"Ground Truth: {sample['output']}\")\n",
        "            print(f\"Top 3 Attention Weights: {attention_weights.cpu().numpy()[:3]}\")\n",
        "\n",
        "    # Calculate accuracy (for classification tasks)\n",
        "    accuracy = accuracy_score(ground_truths, predictions)\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    return predictions, ground_truths, accuracy\n"
      ],
      "metadata": {
        "id": "IvR2WDUVFXpX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== Main Execution ====================\n",
        "def main():\n",
        "    print(\"=\"*60)\n",
        "    print(\"PPlug: Personalized LLM Implementation\")\n",
        "    print(\"Based on: LLMs + Persona-Plug = Personalized LLMs\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load data\n",
        "    print(\"\\n1. Loading datasets...\")\n",
        "    train_dataset = LaMP_Dataset(task=\"LaMP-2\", split=\"train\", sample_size=config.sample_size)\n",
        "    test_dataset = LaMP_Dataset(task=\"LaMP-2\", split=\"test\", sample_size=100)\n",
        "    print(f\"Train size: {len(train_dataset)}, Test size: {len(test_dataset)}\")\n",
        "\n",
        "    # Initialize model\n",
        "    print(\"\\n2. Initializing PPlug model...\")\n",
        "    model = PPlugModel(config).to(device)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total parameters: {total_params:,}\")\n",
        "    print(f\"Trainable parameters: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\n3. Training PPlug model...\")\n",
        "    model = train_pplug(model, train_dataset, config)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"\\n4. Evaluating PPlug model...\")\n",
        "    predictions, ground_truths, accuracy = evaluate_pplug(model, test_dataset)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training and Evaluation Complete!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return model, predictions, ground_truths\n"
      ],
      "metadata": {
        "id": "fi2LbklzFjNG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, predictions, ground_truths = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f707942e93bc45b6ab3f9461870cff44",
            "b920c93cddef4960a9c5c56b9526e5a3",
            "6ce20d4be53346fa837c2e71e0b4c641",
            "06e62563acd04aa295f3e1ad21eb6179",
            "35124b7d84d54eaa8b2aa8033d4f06bf",
            "822610a2023a471891435b5c9ea7614f",
            "cd53c860094a4c53b13e8c3e98efcf29",
            "f423c84a481046bb808aaa20fa982e24",
            "1db7189134eb44c782ab3fdedb0ac389",
            "013e88bb4a514425ba5a5d246f666921",
            "a66b0d42ff184634a884d6af78bd0964",
            "4015e7232d894953963de5429029029c",
            "81f672f9d10e49f68baf653e5ac10570",
            "7a7a05a4833f43a48a6f7f394b756eaf",
            "e28734f75d6843f89c7c4ae67d0f4bf1",
            "3d24032ddbd34e899811b6f11abb4b64",
            "8eac22fd6ea3449fb63cfb009e9ce079",
            "d70d49353a3c4cb2b5d28f0938c38bee",
            "b39d0539711d4d18a945f9fcdd10d5aa",
            "2fd674d9dc934327b084edb8b9bd0919",
            "e2b11430d2e942b18d82aaddc8410e58",
            "fc31a2f5a6854a4b9bb9d0971e9b35e3"
          ]
        },
        "id": "_HGbpj5pFnrH",
        "outputId": "baee9690-b68a-4b74-9dd4-9a709264057a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PPlug: Personalized LLM Implementation\n",
            "Based on: LLMs + Persona-Plug = Personalized LLMs\n",
            "============================================================\n",
            "\n",
            "1. Loading datasets...\n",
            "Loading LaMP-2 train dataset...\n",
            "Loading LaMP-2 test dataset...\n",
            "Train size: 500, Test size: 100\n",
            "\n",
            "2. Initializing PPlug model...\n",
            "Total parameters: 358,242,048\n",
            "Trainable parameters: 1,181,952 (0.33%)\n",
            "\n",
            "3. Training PPlug model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/2:   0%|          | 0/125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f707942e93bc45b6ab3f9461870cff44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 completed. Average loss: 4.7668\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2/2:   0%|          | 0/125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4015e7232d894953963de5429029029c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 completed. Average loss: 4.7496\n",
            "\n",
            "4. Evaluating PPlug model...\n",
            "\n",
            "==================================================\n",
            "EVALUATION EXAMPLES\n",
            "==================================================\n",
            "\n",
            "--- Example 1 ---\n",
            "User ID: user_0\n",
            "Input: Movie: Test Film 0. Description: An exciting documentary adventure....\n",
            "Predicted: It's a documentary about a group of people who are trying to make a difference in the lives of people around them.\n",
            "Ground Truth: Documentary\n",
            "Top 3 Attention Weights: [0.12864499 0.12045685 0.12573704]\n",
            "\n",
            "--- Example 2 ---\n",
            "User ID: user_1\n",
            "Input: Movie: Test Film 1. Description: An exciting drama adventure....\n",
            "Predicted: I'm not sure what to say about this movie.\n",
            "Ground Truth: Thriller\n",
            "Top 3 Attention Weights: [0.06462295 0.07288479 0.06433724]\n",
            "\n",
            "--- Example 3 ---\n",
            "User ID: user_2\n",
            "Input: Movie: Test Film 2. Description: An exciting drama adventure....\n",
            "Predicted: It's a good movie. It's a good movie.\n",
            "Ground Truth: Sci-Fi\n",
            "Top 3 Attention Weights: [0.07355953 0.08156873 0.08034724]\n",
            "\n",
            "--- Example 4 ---\n",
            "User ID: user_3\n",
            "Input: Movie: Test Film 3. Description: An exciting documentary adventure....\n",
            "Predicted: This is an exciting documentary adventure.\n",
            "Ground Truth: Drama\n",
            "Top 3 Attention Weights: [0.12065063 0.12524137 0.12321002]\n",
            "\n",
            "--- Example 5 ---\n",
            "User ID: user_4\n",
            "Input: Movie: Test Film 4. Description: An exciting documentary adventure....\n",
            "Predicted: This is an exciting documentary adventure.\n",
            "Ground Truth: Thriller\n",
            "Top 3 Attention Weights: [0.11148212 0.11189203 0.11158522]\n",
            "\n",
            "==================================================\n",
            "Accuracy: 0.0000\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "Training and Evaluation Complete!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQ3ic4KGFpv1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}