{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DataSavvyYT/experiments/blob/main/1_llm_finetune/1_tune_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "430zhOo5Powm",
    "outputId": "95c83b2a-94e4-4683-d2b0-6b84c4144216"
   },
   "outputs": [],
   "source": [
    "# Install deps (Colab)\n",
    "%pip -q install -U transformers accelerate datasets peft bitsandbytes trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHSCVd-NqFQY"
   },
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saeL162xIZ-t"
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "BASE_MODEL = \"google/gemma-2-2b-it\"  # or gemma-2-2b, choose -it for instruction-tuned base\n",
    "OUTPUT_DIR = \"gemma-promo-qlora\"\n",
    "MAX_SEQ_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUM = 4\n",
    "EPOCHS = 3\n",
    "LR = 2e-4\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.05\n",
    "DATASET_PATH = \"json\"  # \"json\" + data_files below, or point to your HF dataset repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "6b4c374f82844bfa90b14a39f6f0d3a6",
      "655aad4649324077b587eb9d9ec7602f",
      "f7c58387b21142539c64be39908364b7",
      "29e77c66988a49038002f271a0ef56cf",
      "65ab007ac3e245a0bb6c86d4ac15deae",
      "b0ba5496863f431ca0077a17c9393cdd",
      "835a29b648064714ac6e8de92775787b",
      "cfa25d299b5746d5b01e2eeec8a12bf7",
      "7c34397766a24f33821c26d8eee565a0",
      "8c7f4ae8d08744f280d02c97d6b9424d",
      "382b06da78dd49a59694cb606eba2783",
      "6ff57faac88842f5a071812e38ae2a54",
      "1dc2ed9c42464b19ae03a7cc398ef887",
      "a0da74602c4744bc846355d89502c8c2",
      "3a392159fd85401bb502a2d752022eda",
      "03d57d37e15e4e75be519076c3aac527",
      "dc665ed02992414f9d2545dc38a79477",
      "c34343f8d14c472784b4f76e535c2143",
      "587dc82686f5418096b703ddaf0e66ea",
      "b1a56b83c1014b37a67d6213b8e7aff2",
      "e9faf8dbf2df44249683b3f1162d9aeb",
      "c770010101194d35b0870b1c3286e4dd"
     ]
    },
    "id": "iAjRHgzhIgip",
    "outputId": "ac9e6a04-4c2d-4ed7-f67c-3d71941b5af7"
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Load dataset\n",
    "# Expect JSONL with fields: instruction, input, output\n",
    "# ----------------------------\n",
    "dataset = load_dataset(\n",
    "    DATASET_PATH,\n",
    "    data_files={\n",
    "        \"train\": \"/content/drive/MyDrive/data/promotion/train.jsonl\",\n",
    "        \"validation\": \"/content/drive/MyDrive/data/promotion/validation.jsonl\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpY_JCRLIjN0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Formatting function to create supervised prompts\n",
    "SYSTEM_PREFIX = \"You are an analyst that predicts promotion effectiveness based on campaign details.\"\n",
    "INSTR_TEMPLATE = \"\"\"<system>\n",
    "{system}\n",
    "</system>\n",
    "<instruction>\n",
    "{instruction}\n",
    "</instruction>\n",
    "<input>\n",
    "{inp}\n",
    "</input>\n",
    "<output>\n",
    "{out}\n",
    "</output>\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "62e987e44ef543b290e75122725a52b8",
      "576796557b694b8a93c3c762e8ded69a",
      "6f0bbdaf32874cabbb1ee1ea9c503f61",
      "b15bc1b732cb484bb8e8a8003e1c39de",
      "452748a5c914445796dbb81d77c6e1e7",
      "b6105c85eaad4dd1a7c651a3188c8fe5",
      "b156c9f52fc14db29f98f4c015e4a2a3",
      "39a0ae1df84d490dadf64b199e8f9870",
      "693a9c1d0ce2411e99c175f214dfde67",
      "82ec07a8b93f41f49283a5ec49821cab",
      "88bdf401ab1a49fdb29ab2919212a4aa",
      "06c9a696e6ff48b181226e87c0494e13",
      "a180b1d4ce5f4cdcb0a2fd9b0c8e81c9",
      "68dcc6af338844b9a3ce2e6a378669a3",
      "559596fd776640a4a4f89249b8aa095a",
      "8522485d81104bfb9e7a9910655c5b08",
      "716c4f4c6c244c85a58fbd6a8cb656ba",
      "279acb19b0744fda9a97b70b8a83b859",
      "2ec77fd15bb446ea9040bced806c81fa",
      "d193f82074a44c21a8682a2aeacf37c4",
      "4d8455c92a7643b693b7c7d4f5ca4b4a",
      "07cdf5835ee844ecab277456dd028707"
     ]
    },
    "id": "K2VSQZ-eIq43",
    "outputId": "368bdceb-f520-4181-816c-ebf32d881ba2"
   },
   "outputs": [],
   "source": [
    "def format_example(example):\n",
    "    instruction = example.get(\"instruction\", \"Predict promotion effectiveness.\")\n",
    "    inp = example.get(\"input\", \"\")\n",
    "    out = example.get(\"output\", \"\")\n",
    "    # SFTTrainer learns to map input -> output; include output as labels portion\n",
    "    return INSTR_TEMPLATE.format(system=SYSTEM_PREFIX, instruction=instruction, inp=inp, out=out)\n",
    "\n",
    "def map_fn(batch):\n",
    "    texts = [format_example(ex) for ex in batch]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "train_ds = dataset[\"train\"].map(lambda ex: {\"text\": format_example(ex)})\n",
    "eval_ds = dataset[\"validation\"].map(lambda ex: {\"text\": format_example(ex)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wktLDYOItne"
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Tokenizer & 4-bit model load (QLoRA)\n",
    "# ----------------------------\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386,
     "referenced_widgets": [
      "7d01c3a0922445d4bde517ec83047a8c",
      "150169ecbe714172bcb6a57d723cd30d",
      "cca1e8ad39a04b4f8f704e0ea8e03c49",
      "4bdc0bb1ccc14203a9bbeb9c2bd27a1a",
      "38b0ebda809541c4a5214b25aed67845",
      "158f4ab0c4584c408b6fa83156c8375e",
      "00cd942f07a24dab8b00c47d32180f68",
      "b8adc4c1fc8c44ae835080a2db7bea63",
      "6f4ffa0d43d64c67a0188305d54d22f1",
      "dfb81fcb030d405f9eae173bb48bf656",
      "6e8423bcd2804a199634c7887617a189",
      "84efc25a72164fa4be1c63655076425a",
      "f742ce2949ae450d8b55fd4a2b8e80d1",
      "8a69b0fa804e431c9a147a8f362519c2",
      "67d777ea1af64005a123cebe42db1726",
      "c7bc2cdaac6e44b9907a0eb3eacd1a72",
      "8e78b54ba4c14fd7af1915e54c28da44",
      "c0dd1693c6e04b3aab1345bbe21000d1",
      "adf2bc222ab7429096d8ff94f0394c6a",
      "1e0f1b3a69794620ac4d572fefecde30",
      "e1d78023f6af4635b0c9563e346b830b",
      "37835575dccc4562a976a8e1e480ac4d",
      "ff9541f8619e4017833290996fe73d14",
      "25303899d0324195bff3e835c2162ef6",
      "bfe917f9d683480aa927ee0712eb9355",
      "787a5952b9b04a3aa43d88f8dd680312",
      "ac0336f5ebf9478987b1cdef5c2466e3",
      "ecd3ad5b78194de686e5bf70b3f99cb3",
      "cb4aff6f1e0645c9a96358de6d8205d6",
      "a619b9cb64f44b43bc4ed81eaeef5373",
      "b03b2159d3d44dbcb99736f5438b60a9",
      "3450748494754152959c167102b02d24",
      "861065014008443bba7c99d8c61299bc",
      "cffa777150064c8a8b6c9e5e3f9380ff",
      "f601ff2dc09e4984871ae63cba0231da",
      "1072db6a08174140b68d2e9b8e9256a2",
      "668db36c0b664dd4835501da948531f8",
      "c7864378e33b4bde8eff44b1afc8db64",
      "4be431dc5f24455a80a8194a5aabc73b",
      "66f7873d84d74a4db2be4779f665f319",
      "35ccfe288abc4e1692edb5827e2a03dd",
      "32a5bf3dcfa04518829ea624c3848fe3",
      "20575ac159b54700a73bbc47f1ad18d1",
      "3a120bcff94e4e0f9b5f659819448f32",
      "5bef0e948b7a441087527f5445f56161",
      "58b7388f1c2b418b8e4b0bbc424c6411",
      "ea698a7f8a884194bfef3d3958a16c38",
      "f9933183691240b69863f6bb58a29da0",
      "1e0bd13087cc40bf83f069068d61d29c",
      "2223be791e4348b3886b381a4b71cee4",
      "559ae9e6058247f1bf9acad6b9ecd4c2",
      "bed5d70209c7487e88dae0e618247203",
      "81d54baf1ebc433593535e07137797e0",
      "f37b061ab07742dc94e55ff0e1f8f794",
      "1d156ae151174fafa47bd847ac714aeb",
      "0ebd7a6a4a374b01a3de177833ee2097",
      "f8bc8c7e141e4b518739d0b5d797f1bc",
      "bde96640f84046c1bbc454a1626e6b2c",
      "c0ded714c5574ec39260c9398fc1a651",
      "db9be0cbaf8f4402a23c36a1ac239294",
      "c865ccbec7e648dd956712a5d8622dfb",
      "9cd3f6d8523e4ed6901f6fbe89ffa888",
      "52124b6ce2f84fa497fc5f3fd24d6f4c",
      "5a4f115a1d3d4c9097adb6e6072be634",
      "cd10c23665c3477a913ac4c8c75cb33e",
      "559f7375559b40b292aec40c84ec78bd",
      "000381bbe68a4414bfd15133496c8dfe",
      "c95c9be89bed499387d35cd1bff53430",
      "f4eaf350f2d54d98a734ac21361abb21",
      "9018bab9af7b45f4805fc84ce2a2d501",
      "0108db4d00064e928d70ffd00b61bf87",
      "0264878ad021457c9dcc5ed2da1420fd",
      "ba80428320d34c38a9d48195c60e8221",
      "37612cc69e2b45e3a51f60f54d71633b",
      "c3821a5801dd4400b2e2a5c96ce47dc5",
      "f3cf63af90c74bb7824354f5ac674443",
      "baf0063bb86343a8916c788c7746868d",
      "9e542610a0a94b09a8cdda4958927d77",
      "7b42ab05dd6f48f480d57bcb29f75833",
      "3088299962e54a26a8c8f147b344ab3e",
      "83c045880ee649fd9910bb8c6fd0514d",
      "88035f2dc1b7455aa4f08dea78089305",
      "fda64940db96401d95e5af5d954b8f06",
      "e1a452ae679d4ef09a863affdcc9684c",
      "afbe64927cd541d38d4f205680f1859e",
      "add5a0782e524ebf8423ae25cb101418",
      "bad921954a7748948582c58f7f9f53cb",
      "89265962c4e9403094e637086ccff1fe",
      "82c61102e50144958352d93c6eb18844",
      "a3236b3b83df490da862721a7335a6e6",
      "c1d80f9bd9f2435f9156f8b7f3416348",
      "9909724ade1541fa94a39029dd886fc2",
      "10f23bc0082a49e1a2c50a5fdb7cee7c",
      "0ead4c6f073740b193ca45f73dcf2d95",
      "6aac44972c3540ee89685b6a6b6e0f1f",
      "eb838ac4eb384247911fc81522ec0380",
      "7dda4614364046eab6fa9ef5af3599fc",
      "49f1bb9c6102453f8a756d74091db8b7",
      "9cda944aa990427381202b66fdde6aca",
      "b26e3a5ed8964ec6bc564bdb1cb5ec76",
      "739f8979879342368a82c7c2e916235b",
      "4753006dd1de4e50bc3ac8520acddfa4",
      "e289b58d16d6464ebcb32a5c3ccbc72b",
      "ad23c71c576b44309102f81fa9251e22",
      "14b6eb44c8b540ca857189a62362b560",
      "3dfb3e7bc1c641e0bf903ace179e28a0",
      "a825c1d5c0514699a2747ed5f9ff89a9",
      "6a89f45ac5784da1972092d1f26d18d8",
      "acd1c1c83949447982827fe153c5a4ed",
      "e73fb2e7070143d9808bb06828a9befb",
      "69aec5b159854575b79f8499277bad9f",
      "bf0261c7a18442089bbc95d60d5aeccc",
      "86b4eb6b6f874f47a27adeead640d8f7",
      "d872100a81764bc985eedaf5cd347529",
      "cd53f459d5b34d5cadd01274343a626c",
      "d09fb6deef1b40d18cfabee98e4d8e72",
      "5a89b8ebf6464c298c5f1376765bbb06",
      "79d6d0b17a2a401780dba14bc78abfab",
      "af24908919824f998f805cffe0fb3d1e",
      "4f8028f7d8f9497b83296a278f49a3f5",
      "a770aa98f887497eac429348e99953ed"
     ]
    },
    "id": "vzesx9pqIwnn",
    "outputId": "c885e9d1-86ef-4d83-bd15-b7393141f8ef"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_Elti_FIzkl"
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# LoRA config (PEFT)\n",
    "# ----------------------------\n",
    "peft_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubRXsyiGI1eF"
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Trainer\n",
    "# ----------------------------\n",
    "sft_args = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    learning_rate=LR,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.03,\n",
    "    logging_steps=20,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    bf16=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558,
     "referenced_widgets": [
      "413d080e7ced4ba9996b612a96e8f809",
      "ad9c662e48484d64a39b0c0fe8de8a7a",
      "073f5cceac3e4631a937c5002dde268b",
      "c18f2ae66a53438ebfb2e574b044dae8",
      "982b62f852604cb09a4a0ace57fe0d25",
      "ca742d9278084f1891d0ffa8cb8ef72c",
      "812376e2e2ad47d78bb893f34fd2ee8f",
      "6dc644000e7c4c1a95237c2623cca32a",
      "0da0e31452ef4e54916c5eaac893ea88",
      "92f83d3c603e48f5a74c76096de3fed3",
      "11f83706e94b4b3b8a4ae4f3883f9d3b",
      "bf42c8afbe09451da88f04175f986fb9",
      "04019fe9f8bc49b19686ca1a4348bd15",
      "5841ecef34cd4992a27a008dcb825fcb",
      "80218b9fdb6b4b9696caf3e828836598",
      "914f22e3317249e399a6399707d652e3",
      "d7f3af97b98645f9b7f219168792187f",
      "b6a5b6e66802444bba60831b1d2d8ea3",
      "4027cef65e5b413f92ad2636822183a4",
      "e9e591ab59a3447d8955e7328a0dce6f",
      "4101499f377f4d63ba9781d3bdc526e5",
      "6b8cefee92334d5a802f895b1635317a"
     ]
    },
    "id": "4c7b8bb6",
    "outputId": "54c65c2b-b683-4914-8b2e-acd533657058"
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_args,\n",
    "    peft_config=peft_config,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_eval_ds,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133,
     "referenced_widgets": [
      "ad0c16780b8442b0a54e543f9f96e11a",
      "8b15d774bfef48e7ac0b7c8476f15f76",
      "412eb4f427434850bfab85c867eaf1ac",
      "c191475969c14dd49ae491818e97a40b",
      "431c7f904b0f4e37968879706882abe1",
      "ddf0c8340f964d639bb790a35c162b21",
      "0ace4bf156c9492882f2315e7bce96eb",
      "298391b06afd4052912243a961929ae0",
      "0d33eb034d39434192324a174ddb165b",
      "5313ee718fec4917b6e6154217c1e537",
      "6df5cbf7c8214ca89ea2c408cdae427d",
      "d7ed43ddb8794da099be4674f39eb1af",
      "443359187e81447287f3bece4de3fada",
      "c64da3dee2df46b389a67fb3aff506a3",
      "5eb7ab61e425469ea412067e46fb4420",
      "931e5c138c4349f0b91d4b3e4940cf2b",
      "b216e08a96344f53925e89fbcf7c58ad",
      "8d96565a90704ace9cc70a6dc997d9cc",
      "664ec684f0714afca00c71c82eb2750e",
      "1702298bbfa240e597e65512d6f6b920",
      "3f1deb45c1e44c579b79e2f57a952748",
      "10eb8f489ded4f18baf6c6df77644345"
     ]
    },
    "id": "CdXiHH7qI49A",
    "outputId": "ba50ff6a-a30e-411e-fcfd-e83f7232d545"
   },
   "outputs": [],
   "source": [
    "# Tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    # Ensure truncation is handled correctly, and pad if necessary for batching (though SFTTrainer handles padding generally)\n",
    "    tokenized = tokenizer(examples[\"text\"], truncation=True, max_length=MAX_SEQ_LEN)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy() # For causal LMs, labels are usually input_ids\n",
    "    return tokenized\n",
    "\n",
    "tokenized_train_ds = train_ds.map(tokenize_function, batched=True, remove_columns=train_ds.column_names)\n",
    "tokenized_eval_ds = eval_ds.map(tokenize_function, batched=True, remove_columns=eval_ds.column_names)\n",
    "\n",
    "# ----------------------------\n",
    "# Optional: Merge LoRA into base weights (for single file deployment)\n",
    "# Note: requires reloading base model in full precision or 8-bit for merge\n",
    "# ----------------------------\n",
    "# from peft import PeftModel\n",
    "# from transformers import AutoModelForCausalLM\n",
    "# base_fp = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "# peft_model = PeftModel.from_pretrained(base_fp, OUTPUT_DIR)\n",
    "# merged = peft_model.merge_and_unload()\n",
    "# merged.save_pretrained(\"gemma-promo-merged\", safe_serialization=True, max_shard_size=\"2GB\")\n",
    "# tokenizer.save_pretrained(\"gemma-promo-merged\")\n",
    "\n",
    "# ----------------------------\n",
    "# Quick eval helper: generate prediction for a sample\n",
    "# ----------------------------\n",
    "def predict_effectiveness(description: str) -> str:\n",
    "    prompt = f\"\"\"<system>\n",
    "{SYSTEM_PREFIX}\n",
    "</system>\n",
    "<instruction>\n",
    "Predict promotion effectiveness as one of: \"effective\", \"not effective\", or a probability between 0 and 1.\n",
    "</instruction>\n",
    "<input>\n",
    "{description}\n",
    "</input>\n",
    "<output>\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**inputs, max_new_tokens=20, do_sample=False)\n",
    "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    # naive parse: take last line after <output>\n",
    "    return text.split(\"<output>\")[-1].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLhnm6UBQQ-h"
   },
   "outputs": [],
   "source": [
    "print(predict_effectiveness(\"Campaign: Diwali Sale; Channel: Email; Budget: 5 Lakh INR; Audience: Returning; Discount: 10%; Duration: 5 days; Past CTR: 2.8%\"))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOaFgnln6S/v7hHPlutVJMJ",
   "gpuType": "T4",
   "include_colab_link": true,
   "mount_file_id": "https://github.com/DataSavvyYT/experiments/blob/main/0_empty_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
